{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag of Words\n",
    "Bag of words is a technique to convert text documents into numeric format where we represent each document as a numeric vector which is equal to the length of the vocabulary. We count the word frequency of each word in a sentence and replace that count with the corresponding word index in that vector.\n",
    "\n",
    "The resultant document term matrix will contain rows equal to the number of documents in the matrix and columns equal to the vocabulary size.\n",
    "\n",
    "Advantages: Very simple and efficient way to represent text in vector format.\n",
    "\n",
    "Drawbacks: We lose word ordering because while we count word frequency, we do not take word ordering into account, which might affect the meaning of a sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\prasa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BagOfWordsVectorizer:\n",
    "    def __init__(self, to_lower=True, regEx=None, remove_stopwords=False, preprocessor=None, tokenizer=nltk.tokenize.TreebankWordTokenizer()):\n",
    "        self._tokenizer = tokenizer\n",
    "        self._to_lower = to_lower\n",
    "        self._remove_stopwords = remove_stopwords\n",
    "        self._PUNCTUATION_RE = '[,.?!;:]'\n",
    "        if regEx is None:\n",
    "            self._regEx = self._PUNCTUATION_RE\n",
    "        else:\n",
    "            self.regEx = regEx\n",
    "        self.vocab_ = []\n",
    "        self._preprocessor = preprocessor             \n",
    "        \n",
    "    \"\"\" preprocess given text, learns vocabulary \"\"\"        \n",
    "    def fit(self, X):\n",
    "        X_processed = []\n",
    "        if self._preprocessor is not None:\n",
    "            X_processed = [self._preprocessor(doc) for doc in X]\n",
    "        else:\n",
    "            X_processed = [self._preprocess(doc) for doc in X]\n",
    "        self.vocab_ = self._get_vocab(X_processed)        \n",
    "\n",
    "    \"\"\" transforms given text to document term matrix, \n",
    "        based on the vocab learned from fit method \"\"\"        \n",
    "    def transform(self, X):\n",
    "        result = []\n",
    "        for doc in X:\n",
    "            vect = [0]*len(self.vocab_)\n",
    "            if type(doc)==np.ndarray:\n",
    "                doc = doc[0]\n",
    "            words = doc.split()\n",
    "            for i, v in enumerate(self.vocab_):\n",
    "                freq = words.count(v)\n",
    "                vect[i] = freq\n",
    "            result.append(vect)\n",
    "        return np.array(result)  \n",
    "\n",
    "    def fit_transform(self, X):\n",
    "        self.fit(X)\n",
    "        return self.transform(X)\n",
    "    \n",
    "    # convert text to lower case, removes punctuaions, tokenizes, remove stop words\n",
    "    def _preprocess(self, doc):        \n",
    "        result = []\n",
    "        if self._to_lower:\n",
    "            if type(doc)==np.ndarray:\n",
    "                doc = doc[0]\n",
    "            doc = doc.lower()\n",
    "        doc = re.sub(self._regEx, '', doc)\n",
    "        tokens = self._tokenizer.tokenize(doc)\n",
    "        for token in tokens:\n",
    "            if self._remove_stopwords:\n",
    "                if token not in stop_words:\n",
    "                    result.append(token)\n",
    "            else:\n",
    "                result.append(token)\n",
    "        return \" \".join(result) \n",
    "    \n",
    "    # creates vocabulary from the processed text \n",
    "    def _get_vocab(self, X):\n",
    "        result = []\n",
    "        for doc in X:           \n",
    "            tokens = str(doc).split()\n",
    "            for token in tokens:\n",
    "                if token not in result:\n",
    "                    result.append(token)\n",
    "        return sorted(result) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take a sample corpus and analyse bag of words model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [['This is movie is a nice movie', 1],\n",
    "          ['Movie is very good', 1],\n",
    "          ['a very bad movie, really bad', 0],\n",
    "          ['this is not a good movie', 0],\n",
    "          ['do not watch this movie', 0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the data into pandas\n",
    "data = pd.DataFrame(corpus, columns=['review', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This is movie is a nice movie</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Movie is very good</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a very bad movie, really bad</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>this is not a good movie</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>do not watch this movie</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          review  label\n",
       "0  This is movie is a nice movie      1\n",
       "1             Movie is very good      1\n",
       "2   a very bad movie, really bad      0\n",
       "3       this is not a good movie      0\n",
       "4        do not watch this movie      0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the reivews from dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[:,0:1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the labels from dataframe\n",
    "y = data.iloc[:,1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Proprocess raw text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#instantiate, fit, transform\n",
    "bowVect = BagOfWordsVectorizer(to_lower=True, remove_stopwords=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_processed = bowVect.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 2, 1, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0],\n",
       "       [2, 0, 0, 0, 1, 0],\n",
       "       [0, 1, 1, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 1]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets visualzie the document term matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm = pd.DataFrame(X_processed, columns=bowVect.vocab_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bad</th>\n",
       "      <th>good</th>\n",
       "      <th>movie</th>\n",
       "      <th>nice</th>\n",
       "      <th>really</th>\n",
       "      <th>watch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bad  good  movie  nice  really  watch\n",
       "0    0     0      2     1       0      0\n",
       "1    0     1      0     0       0      0\n",
       "2    2     0      0     0       1      0\n",
       "3    0     1      1     0       0      0\n",
       "4    0     0      1     0       0      1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtm.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note:  This document term matrix can be used to train a classifer and make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = ['This movie is a nice movie', 'Movie is very good', 'a very bad movie really bad']          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "bowVect = BagOfWordsVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 1, 2, 1, 0, 0, 0],\n",
       "       [0, 0, 1, 1, 0, 0, 0, 0, 1],\n",
       "       [1, 2, 0, 0, 1, 0, 1, 0, 1]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bowVect.fit_transform(corpus2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'bad', 'good', 'is', 'movie', 'nice', 'really', 'this', 'very']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bowVect.vocab_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
